{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c09cfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T05:29:41.016776Z",
     "start_time": "2022-11-02T05:29:41.013556Z"
    }
   },
   "source": [
    "---\n",
    "title: Draft - Stable diffusion using ðŸ¤— Hugging Face - Looking under the hood.\n",
    "author: Aayush Agrawal\n",
    "date: \"2022-11-04\"\n",
    "categories: [Stable Diffusion]\n",
    "image: \"underthehood.png\"\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "        number-sections: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076cbf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T05:30:53.455608Z",
     "start_time": "2022-11-02T05:30:53.452620Z"
    }
   },
   "source": [
    "> A introduction into what goes on in the pipe function of  ðŸ¤— [hugging face diffusers library](https://github.com/huggingface/diffusers) `StableDiffusionPipeline` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f38158",
   "metadata": {},
   "source": [
    "This is my second post of the Stable diffusion series, if you haven't checkout the first one, you can read it here - <br>\n",
    "1. **Part 1** - [Introduction to Stable diffusion using ðŸ¤— Hugging Face](https://aayushmnit.com/posts/2022-11-02-StabeDiffusionP1/2022-11-02-StableDiffusionP1.html).\n",
    "\n",
    "\n",
    "In this post, we will understand basic components of stable diffusion pipeline and their purpose. Later we will reconstruct `StableDiffusionPipeline.from_pretrained` function using these components. Let's get started - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e60a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T06:01:08.829864Z",
     "start_time": "2022-11-02T06:01:08.826893Z"
    }
   },
   "source": [
    "<figure>\n",
    "<img src=\"./underthehood.png\" style=\"width:100%\">\n",
    "<figcaption align = \"center\">\n",
    "        Fig. 1: This image was generated by ðŸ¤— Stable diffusion model using \"a scientist looking under the hood of a car realistic 4k image\" prompt.\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da93c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T05:35:56.657250Z",
     "start_time": "2022-11-02T05:35:56.654876Z"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af719f8",
   "metadata": {},
   "source": [
    "Diffusion models as seen from the previous post can generate high-quality images. Stable diffusion models are special kind of diffusion models called **Latent Diffusion** model. They were first proposed in this paper [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752). The original Diffusion model tend to consume a lot more memory, so latent diffusion models were created which can do the diffusion process in lower dimension space called `Latent` Space. On a high level, diffusion models are machine learning models that are trained to `denoise` random Gaussian noise step by step, to get the result i.e. `image`. In `latent diffusion` the model is trained to do this same process in lower dimension. <br>\n",
    "\n",
    "There are three main components in latent diffusion - <br>\n",
    "\n",
    "1. A text encoder, in this case a [CLIP's Text encoder](https://openai.com/blog/clip/) \n",
    "2. An autoencoder, in this case a Variational Auto Encoder also referred as VAE \n",
    "3. A [U-Net](https://arxiv.org/abs/1505.04597)\n",
    "\n",
    "Let's dive into each of these components and understand their use in diffusion process. The way I will be attempting to explain these components is talking about them in following 3 stages - <br>\n",
    "\n",
    "1. **_What goes in the component and what comes out of the component_** - This is really important, and key part of [top down learning approach](https://www.fast.ai/posts/2016-10-08-teaching-philosophy.html) of understanding \"the whole game\".\n",
    "2. **_What's their role in Stable diffusion pipeline_** - This will build your intuition around how this component fit in Stable diffusion process. This will help your intuition on the diffusion process\n",
    "3. **_How they are originally trained_** - This part will provide more understanding on training of these individual components and how they come in existence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b753c1c",
   "metadata": {},
   "source": [
    "## CLIP Text Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1f98a",
   "metadata": {},
   "source": [
    "To be written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef60112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T06:41:37.913002Z",
     "start_time": "2022-11-02T06:41:37.909926Z"
    }
   },
   "source": [
    "## VAE - Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94342fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:01:45.150128Z",
     "start_time": "2022-11-03T07:01:45.147173Z"
    }
   },
   "source": [
    "To be written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607dc05",
   "metadata": {},
   "source": [
    "## U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7818b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:01:45.150128Z",
     "start_time": "2022-11-03T07:01:45.147173Z"
    }
   },
   "source": [
    "To be written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3ea8aa",
   "metadata": {},
   "source": [
    "## Stable Diffusion Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ae4ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:01:45.150128Z",
     "start_time": "2022-11-03T07:01:45.147173Z"
    }
   },
   "source": [
    "To be written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042160c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4993c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:01:45.150128Z",
     "start_time": "2022-11-03T07:01:45.147173Z"
    }
   },
   "source": [
    "To be written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2360b8",
   "metadata": {},
   "source": [
    "I hope you enjoyed reading it, and feel free to use my code and try it out for generating your images. Also, if there is any feedback on the code or just the blog post, feel free to reach out on [LinkedIn](https://www.linkedin.com/in/aayushmnit/) or email me at aayushmnit@gmail.com."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
